{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d52b1d-5a87-491b-9113-859d11574c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import cm\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.ndimage import label, find_objects, binary_erosion, binary_dilation, distance_transform_edt\n",
    "from scipy import stats as scipy_stats\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial import Delaunay, distance\n",
    "from sklearn.cluster import DBSCAN\n",
    "from skimage import filters\n",
    "from skimage.filters import threshold_otsu, threshold_multiotsu\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import fsolve\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf3bab-18d3-4128-8d6b-c2904870fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder structure\n",
    "input_dir = 'input_data'\n",
    "output_dir = 'output_data'\n",
    "\n",
    "# Input staleite data, i.e.: https://browser.dataspace.copernicus.eu/\n",
    "optical_image_path = os.path.join(input_dir, 'Malbork_2024-10-01-00_00_2024-10-01-23_59_Sentinel-2_Quarterly_Mosaics_True_Color_Cloudless.jpg')\n",
    "sar_image_path = os.path.join(input_dir, 'Malbork_2025-04-08-00_00_2025-04-08-23_59_Sentinel-1_IW_VV+VH_VV_-_decibel_gamma0.jpg')\n",
    "\n",
    "# Extract base name for input files (without extension)\n",
    "base_name = os.path.splitext(os.path.basename(optical_image_path))[0].split('_optical')[0]\n",
    "\n",
    "# Define resolution: i.e. 20m per pixel\n",
    "satellite_pixel_resolution = 15\n",
    "\n",
    "# Set ticks intervals for different plots\n",
    "image_x_tick_interval = 5000  # meters (5km)\n",
    "image_y_tick_interval = image_x_tick_interval  # meters (5km)\n",
    "gradient_x_tick_interval = 1000  # meters (1km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c54f6f5-6314-4052-82e9-44b9bb08925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose color histogram tool\n",
    "def decompose_histogram(image, num_peaks=3, value_range=(0, 2), num_bins=50, exclude_zeros=False):\n",
    "    \"\"\"\n",
    "    Decompose an image histogram into a specified number of Gaussian components.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : 2D numpy array\n",
    "        The input image to be analyzed\n",
    "    num_peaks : int\n",
    "        Number of Gaussian peaks to fit (default: 3)\n",
    "    value_range : tuple\n",
    "        Range of values to consider for the histogram (default: (0, 2))\n",
    "    num_bins : int\n",
    "        Number of bins for the histogram (default: 50)\n",
    "    exclude_zeros : bool\n",
    "        Whether to exclude zero values from the analysis (default: False)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing the fitted parameters and component data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Flatten the image data\n",
    "    flat_data = image.flatten()\n",
    "    \n",
    "    # Exclude zeros if requested\n",
    "    if exclude_zeros:\n",
    "        flat_data = flat_data[flat_data != 0]\n",
    "        \n",
    "        # Check if we have any data left after excluding zeros\n",
    "        if len(flat_data) == 0:\n",
    "            print(\"Warning: No non-zero data points found. Cannot perform analysis.\")\n",
    "            return None\n",
    "            \n",
    "        print(f\"Excluded zeros. Analyzing {len(flat_data)} non-zero values.\")\n",
    "    \n",
    "    # Create histogram data\n",
    "    hist, bin_edges = np.histogram(flat_data, bins=num_bins, range=value_range)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    \n",
    "    # Define a function for multiple Gaussian components\n",
    "    def multi_gaussian(x, *params):\n",
    "        \"\"\"\n",
    "        Sum of multiple Gaussian distributions.\n",
    "        params format: [a1, mu1, sigma1, a2, mu2, sigma2, ...]\n",
    "        \"\"\"\n",
    "        y = np.zeros_like(x)\n",
    "        for i in range(0, len(params), 3):\n",
    "            a = params[i]\n",
    "            mu = params[i+1]\n",
    "            sigma = params[i+2]\n",
    "            y += a * np.exp(-(x - mu)**2 / (2 * sigma**2))\n",
    "        return y\n",
    "    \n",
    "    # Define a single Gaussian function for intersection analysis\n",
    "    def single_gaussian(x, a, mu, sigma):\n",
    "        \"\"\"Single Gaussian distribution.\"\"\"\n",
    "        return a * np.exp(-(x - mu)**2 / (2 * sigma**2))\n",
    "    \n",
    "    # Create initial guess and bounds for parameters\n",
    "    initial_guess = []\n",
    "    lower_bounds = []\n",
    "    upper_bounds = []\n",
    "    \n",
    "    max_amplitude = np.max(hist)\n",
    "    value_min, value_max = value_range\n",
    "    range_width = value_max - value_min\n",
    "    \n",
    "    # Get peak indices from histogram to improve initial guesses\n",
    "    # Find local maxima in the histogram\n",
    "    from scipy.signal import find_peaks\n",
    "    peak_indices, _ = find_peaks(hist, height=max(hist) * 0.2)\n",
    "    \n",
    "    # If we found some peaks, use them for initial guesses\n",
    "    if len(peak_indices) > 0 and len(peak_indices) <= num_peaks:\n",
    "        peak_positions = bin_centers[peak_indices]\n",
    "        peak_heights = hist[peak_indices]\n",
    "        \n",
    "        # Sort by height, descending\n",
    "        sorted_indices = np.argsort(peak_heights)[::-1]\n",
    "        peak_positions = peak_positions[sorted_indices]\n",
    "        peak_heights = peak_heights[sorted_indices]\n",
    "        \n",
    "        # Use detected peaks first, then add evenly spaced ones if needed\n",
    "        for i in range(num_peaks):\n",
    "            if i < len(peak_positions):\n",
    "                # Use detected peak\n",
    "                amplitude = peak_heights[i]\n",
    "                mean = peak_positions[i]\n",
    "            else:\n",
    "                # Add evenly spaced peaks for remaining\n",
    "                amplitude = max_amplitude / (num_peaks * 2)\n",
    "                mean = value_min + range_width * (i + 0.5) / num_peaks\n",
    "            \n",
    "            # Amplitude\n",
    "            initial_guess.append(amplitude)\n",
    "            lower_bounds.append(0)\n",
    "            upper_bounds.append(np.inf)\n",
    "            \n",
    "            # Mean\n",
    "            initial_guess.append(mean)\n",
    "            lower_bounds.append(value_min)\n",
    "            upper_bounds.append(value_max)\n",
    "            \n",
    "            # Standard deviation - wider initial guess for better convergence\n",
    "            initial_guess.append(range_width / (4 * num_peaks))\n",
    "            lower_bounds.append(range_width / (50 * num_peaks))  # Allow narrower peaks\n",
    "            upper_bounds.append(range_width)  # Allow wider peaks\n",
    "    else:\n",
    "        # Fall back to evenly spaced means if peak detection fails\n",
    "        for i in range(num_peaks):\n",
    "            # Amplitude\n",
    "            initial_guess.append(max_amplitude / num_peaks)\n",
    "            lower_bounds.append(0)\n",
    "            upper_bounds.append(np.inf)\n",
    "            \n",
    "            # Mean (evenly distribute initial guesses across the range)\n",
    "            mean_guess = value_min + range_width * (i + 0.5) / num_peaks\n",
    "            initial_guess.append(mean_guess)\n",
    "            lower_bounds.append(value_min)\n",
    "            upper_bounds.append(value_max)\n",
    "            \n",
    "            # Standard deviation - wider initial guess for better convergence\n",
    "            initial_guess.append(range_width / (4 * num_peaks))\n",
    "            lower_bounds.append(range_width / (50 * num_peaks))  # Allow narrower peaks\n",
    "            upper_bounds.append(range_width)  # Allow wider peaks\n",
    "    \n",
    "    # Perform the curve fit with increased max iterations and tweaked optimization parameters\n",
    "    try:\n",
    "        params, covariance = curve_fit(\n",
    "            multi_gaussian, \n",
    "            bin_centers, \n",
    "            hist, \n",
    "            p0=initial_guess,\n",
    "            bounds=(lower_bounds, upper_bounds),\n",
    "            maxfev=10000,  # Increase maximum function evaluations\n",
    "            method='trf',  # Use Trust Region Reflective algorithm\n",
    "            ftol=1e-6,     # Function tolerance for termination\n",
    "            xtol=1e-6      # Parameter tolerance for termination\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Fitting error: {e}\")\n",
    "        print(\"Trying alternative optimization approach...\")\n",
    "        \n",
    "        # Try a simpler approach: reduce constraints and use different method\n",
    "        try:\n",
    "            # Remove bounds and use different method\n",
    "            params, covariance = curve_fit(\n",
    "                multi_gaussian, \n",
    "                bin_centers, \n",
    "                hist, \n",
    "                p0=initial_guess,\n",
    "                maxfev=20000,      # More iterations\n",
    "                method='lm'        # Levenberg-Marquardt algorithm (no bounds but can be more robust)\n",
    "            )\n",
    "            print(\"Alternative fitting approach succeeded!\")\n",
    "        except RuntimeError as e2:\n",
    "            print(f\"Alternative fitting also failed: {e2}\")\n",
    "            return None\n",
    "    \n",
    "    # Calculate the fitted values\n",
    "    fitted_y = multi_gaussian(bin_centers, *params)\n",
    "    \n",
    "    # Calculate individual Gaussian components\n",
    "    components = []\n",
    "    for i in range(0, len(params), 3):\n",
    "        a = params[i]\n",
    "        mu = params[i+1]\n",
    "        sigma = params[i+2]\n",
    "        component = a * np.exp(-(bin_centers - mu)**2 / (2 * sigma**2))\n",
    "        components.append(component)\n",
    "    \n",
    "    # Calculate the contribution of each component\n",
    "    total_area = np.sum(fitted_y)\n",
    "    contributions = [np.sum(comp) / total_area * 100 for comp in components]\n",
    "    \n",
    "    # Calculate intersections between adjacent Gaussian components\n",
    "    intersections = []\n",
    "    \n",
    "    # Function to find intersection point between two Gaussian curves\n",
    "    def find_intersection(params1, params2, x_guess):\n",
    "        a1, mu1, sigma1 = params1\n",
    "        a2, mu2, sigma2 = params2\n",
    "        \n",
    "        def func(x):\n",
    "            return single_gaussian(x, a1, mu1, sigma1) - single_gaussian(x, a2, mu2, sigma2)\n",
    "        \n",
    "        try:\n",
    "            result = fsolve(func, x_guess)\n",
    "            # Check if the solution is within our range\n",
    "            if value_min <= result[0] <= value_max:\n",
    "                # Verify it's actually an intersection\n",
    "                y1 = single_gaussian(result[0], a1, mu1, sigma1)\n",
    "                y2 = single_gaussian(result[0], a2, mu2, sigma2)\n",
    "                if np.isclose(y1, y2, rtol=1e-3) and y1 > 0:\n",
    "                    return result[0], y1\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return None, None\n",
    "    \n",
    "    # Sort the components by their means\n",
    "    component_indices = list(range(num_peaks))\n",
    "    component_indices.sort(key=lambda i: params[i*3+1])\n",
    "    \n",
    "    intersection_data = []\n",
    "    \n",
    "    # Find intersections between adjacent components\n",
    "    for i in range(len(component_indices)-1):\n",
    "        idx1 = component_indices[i]\n",
    "        idx2 = component_indices[i+1]\n",
    "        \n",
    "        # Extract parameters for each component\n",
    "        params1 = params[idx1*3:idx1*3+3]\n",
    "        params2 = params[idx2*3:idx2*3+3]\n",
    "        \n",
    "        # Initial guess for intersection: midpoint between means\n",
    "        x_guess = (params1[1] + params2[1]) / 2\n",
    "        \n",
    "        # Find intersection\n",
    "        x_intersect, y_intersect = find_intersection(params1, params2, x_guess)\n",
    "        \n",
    "        if x_intersect is not None:\n",
    "            intersections.append((x_intersect, y_intersect))\n",
    "            intersection_data.append({\n",
    "                'components': (idx1+1, idx2+1),\n",
    "                'x_value': x_intersect,\n",
    "                'y_value': y_intersect,\n",
    "                'relative_height': y_intersect / max(np.max(components[idx1]), np.max(components[idx2]))\n",
    "            })\n",
    "    \n",
    "    # Create a summary plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot original histogram envelope\n",
    "    plt.plot(bin_centers, hist, 'ko', label='Original Data', alpha=0.5)\n",
    "    \n",
    "    # Plot the combined fit\n",
    "    plt.plot(bin_centers, fitted_y, 'r-', linewidth=2, label='Combined Fit')\n",
    "    \n",
    "    # Plot individual Gaussian components\n",
    "    colors = ['g', 'b', 'm', 'c', 'y', 'orange', 'purple', 'brown', 'pink', 'gray']\n",
    "    component_params = []\n",
    "    \n",
    "    for i in range(num_peaks):\n",
    "        idx = i * 3\n",
    "        a = params[idx]\n",
    "        mu = params[idx+1]\n",
    "        sigma = params[idx+2]\n",
    "        contrib = contributions[i]\n",
    "        \n",
    "        color = colors[i % len(colors)]\n",
    "        plt.plot(bin_centers, components[i], f'{color}--', linewidth=1.5, \n",
    "                 label=f'Gaussian {i+1}: μ={mu:.2f}, σ={sigma:.2f}, {contrib:.1f}%')\n",
    "        \n",
    "        component_params.append({\n",
    "            'amplitude': a,\n",
    "            'mean': mu,\n",
    "            'std_dev': sigma,\n",
    "            'contribution': contrib\n",
    "        })\n",
    "    \n",
    "    # Mark intersection points\n",
    "    for x, y in intersections:\n",
    "        plt.plot(x, y, 'ro', markersize=8)\n",
    "        plt.axvline(x=x, color='k', linestyle=':', alpha=0.5)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Pixel Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    if exclude_zeros:\n",
    "        plt.title(f'Decomposition of Histogram into {num_peaks} Gaussian Components (Zeros Excluded)')\n",
    "    else:\n",
    "        plt.title(f'Decomposition of Histogram into {num_peaks} Gaussian Components')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print the fitted parameters\n",
    "    print(f\"Fitted Parameters for {num_peaks} Gaussian Components:\")\n",
    "    for i, comp in enumerate(component_params):\n",
    "        print(f\"Gaussian {i+1}: Amplitude={comp['amplitude']:.1f}, \"\n",
    "              f\"Mean={comp['mean']:.3f}, StdDev={comp['std_dev']:.3f}, \"\n",
    "              f\"Contribution={comp['contribution']:.1f}%\")\n",
    "    \n",
    "    # Print intersection information\n",
    "    if intersection_data:\n",
    "        print(\"\\nIntersection Points Between Gaussian Components:\")\n",
    "        for i, idata in enumerate(intersection_data):\n",
    "            print(f\"Intersection {i+1}: Between Gaussian {idata['components'][0]} and {idata['components'][1]}\")\n",
    "            print(f\"  Position: x={idata['x_value']:.3f}, y={idata['y_value']:.1f}\")\n",
    "            print(f\"  Relative height: {idata['relative_height']*100:.1f}% of max component height\")\n",
    "    else:\n",
    "        print(\"\\nNo valid intersections found between Gaussian components.\")\n",
    "    \n",
    "    # Return results\n",
    "    return {\n",
    "        'bin_centers': bin_centers,\n",
    "        'histogram': hist,\n",
    "        'fitted_curve': fitted_y,\n",
    "        'components': components,\n",
    "        'component_params': component_params,\n",
    "        'raw_params': params,\n",
    "        'intersections': intersection_data\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f424895-1bb0-47d3-a60b-27dc780aea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process optical image\n",
    "optical_image = cv2.imread(optical_image_path)\n",
    "optical_image_rgb = cv2.cvtColor(optical_image, cv2.COLOR_BGR2RGB)\n",
    "optical_image_gray = cv2.cvtColor(optical_image, cv2.COLOR_BGR2GRAY)  # Simplified conversion\n",
    "\n",
    "# Edge detection with Sobel\n",
    "optical_image_sobelx = cv2.Sobel(optical_image_gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "optical_image_sobely = cv2.Sobel(optical_image_gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "optical_image_sobel_combined = cv2.magnitude(optical_image_sobelx, optical_image_sobely)\n",
    "optical_image_sobel_combined = cv2.normalize(optical_image_sobel_combined, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "\n",
    "# Create edge density map\n",
    "kernel_size = 15\n",
    "optical_image_density_map = cv2.GaussianBlur(optical_image_sobel_combined, (kernel_size, kernel_size), 0)\n",
    "# Fix: Convert to float before normalizing\n",
    "optical_image_density_map = optical_image_density_map.astype(float) / np.max(optical_image_density_map)\n",
    "\n",
    "# Load and normalize SAR image\n",
    "sar_image = cv2.imread(sar_image_path, cv2.IMREAD_GRAYSCALE).astype(float) / 255.0\n",
    "\n",
    "# Combine images and apply Non-Local Means smoothing\n",
    "combined_image = optical_image_density_map + sar_image\n",
    "combined_image_uint8 = np.clip(combined_image * 127.5, 0, 255).astype(np.uint8)\n",
    "smoothed_image_uint8 = cv2.fastNlMeansDenoising(combined_image_uint8, None, 10, 7, 21)\n",
    "combined_image = smoothed_image_uint8.astype(float) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffb395c-7f3d-4417-9ca9-f859c45b6bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define water_threshold and urban_threshold based of histograms decomposition\n",
    "result = decompose_histogram(combined_image, num_peaks=3, exclude_zeros=False)\n",
    "intersection_x_values = []\n",
    "if result and 'intersections' in result:\n",
    "    for intersection in result['intersections']:\n",
    "        intersection_x_values.append(intersection['x_value'])\n",
    "\n",
    "# Define thresholds for segmentation\n",
    "water_threshold = intersection_x_values[0]\n",
    "urban_threshold = intersection_x_values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36332bb-47f5-475d-b241-8162a49bad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial segmentation\n",
    "segmentation = np.zeros_like(combined_image, dtype=np.uint8)\n",
    "segmentation[(combined_image < water_threshold)] = 1  # Water\n",
    "segmentation[(combined_image >= water_threshold) & (combined_image < urban_threshold)] = 2  # Terrain\n",
    "segmentation[(combined_image >= urban_threshold)] = 3  # Urban\n",
    "\n",
    "# Process urban mask\n",
    "urban_mask = (segmentation == 3).astype(np.uint8) * 255\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "urban_mask_closed = cv2.morphologyEx(\n",
    "    cv2.dilate(urban_mask, kernel, iterations=1), \n",
    "    cv2.MORPH_CLOSE, \n",
    "    kernel\n",
    ")\n",
    "\n",
    "# Filter small urban patches\n",
    "num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(urban_mask_closed, connectivity=8)\n",
    "urban_mask_filtered = np.zeros_like(urban_mask_closed)\n",
    "for i in range(1, num_labels):\n",
    "    if stats[i, cv2.CC_STAT_AREA] >= 100:  # min_urban_area = 100\n",
    "        urban_mask_filtered[labels == i] = 255\n",
    "\n",
    "# Create final segmentation\n",
    "improved_segmentation = segmentation.copy()\n",
    "improved_segmentation[improved_segmentation == 3] = 2  # Reset urban to terrain\n",
    "improved_segmentation[urban_mask_filtered == 255] = 3  # Set filtered urban areas\n",
    "\n",
    "# Apply colormap for visualization\n",
    "colormap = np.array([\n",
    "    [0, 0, 0],      # Background\n",
    "    [0, 0, 255],    # Water (blue)\n",
    "    [0, 255, 0],    # Terrain (green)\n",
    "    [255, 0, 0]     # Urban (red)\n",
    "], dtype=np.uint8)\n",
    "segmented_image = colormap[improved_segmentation]\n",
    "\n",
    "# Create masks for density analysis\n",
    "urban_mask = improved_segmentation == 3\n",
    "urban_mask_numeric = urban_mask.astype(float)\n",
    "urban_density = combined_image * urban_mask_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5b821-6adf-44ef-b9b0-d7b265e83ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define urban_center_threshold based of histograms decomposition\n",
    "result = decompose_histogram(urban_density, num_peaks=2, exclude_zeros=True)\n",
    "intersection_x_values = []\n",
    "if result and 'intersections' in result:\n",
    "    for intersection in result['intersections']:\n",
    "        intersection_x_values.append(intersection['x_value'])\n",
    "\n",
    "# Define thresholds for urban center segmentation\n",
    "urban_center_threshold = intersection_x_values[0]\n",
    "urban_centers_mask = (combined_image > urban_center_threshold) & urban_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d874f6-3a98-42f1-89d1-ec683931f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set axes in meters\n",
    "def set_axes_in_meters(ax, img_shape):\n",
    "    height, width = img_shape[:2]\n",
    "    # Create x and y axes in meters\n",
    "    x_meters = np.arange(0, width * satellite_pixel_resolution, satellite_pixel_resolution)\n",
    "    y_meters = np.arange(0, height * satellite_pixel_resolution, satellite_pixel_resolution)\n",
    "    \n",
    "    # Set ticks at regular intervals (5km)\n",
    "    image_x_tick_interval = 5000  # meters (5km)\n",
    "    image_y_tick_interval = 5000  # meters (5km)\n",
    "    \n",
    "    x_ticks = np.arange(0, width * satellite_pixel_resolution, image_x_tick_interval)\n",
    "    y_ticks = np.arange(0, height * satellite_pixel_resolution, image_y_tick_interval)\n",
    "    \n",
    "    ax.set_xticks(x_ticks / satellite_pixel_resolution)\n",
    "    ax.set_yticks(y_ticks / satellite_pixel_resolution)\n",
    "    ax.set_xticklabels([f'{int(x/1000)}km' for x in x_ticks])\n",
    "    ax.set_yticklabels([f'{int(y/1000)}km' for y in y_ticks])\n",
    "    \n",
    "    ax.set_xlabel('Distance (km)')\n",
    "    ax.set_ylabel('Distance (km)')\n",
    "\n",
    "# Individual Plots - saves each image as a separate file\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "# 1. Original Image\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plt.imshow(optical_image_rgb)\n",
    "plt.title('Original Optical Image')\n",
    "set_axes_in_meters(ax, optical_image_rgb.shape)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/{base_name}_original.png', dpi=300, bbox_inches='tight')\n",
    "print(f'{output_dir}/{base_name}_original.png file saved')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 2. Sobel Edge Detection\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plt.imshow(optical_image_sobel_combined, cmap='gray')\n",
    "plt.title('Sobel Edge Detection')\n",
    "set_axes_in_meters(ax, optical_image_sobel_combined.shape)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/{base_name}_sobel.png', dpi=300, bbox_inches='tight')\n",
    "print(f'{output_dir}/{base_name}_sobel.png file saved')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 3. Edge Density Map\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plt.imshow(optical_image_density_map, cmap='gray')\n",
    "plt.title('Edge Density Map (0-1 range)')\n",
    "set_axes_in_meters(ax, optical_image_density_map.shape)\n",
    "# Add colorbar with fixed size\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(ax.images[0], cax=cax)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/{base_name}_density.png', dpi=300, bbox_inches='tight')\n",
    "print(f'{output_dir}/{base_name}_density.png file saved')\n",
    "#plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 4. SAR Image\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plt.imshow(sar_image, cmap='gray')\n",
    "plt.title('SAR Image (0-1 range)')\n",
    "set_axes_in_meters(ax, sar_image.shape)\n",
    "# Add colorbar with fixed size\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(ax.images[0], cax=cax)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/{base_name}_sar.png', dpi=300, bbox_inches='tight')\n",
    "print(f'{output_dir}/{base_name}_sar.png file saved')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 5. Combined Result\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "im = plt.imshow(combined_image, cmap='viridis')\n",
    "plt.title('Combined Result (0-2 range)')\n",
    "set_axes_in_meters(ax, combined_image.shape)\n",
    "# Add colorbar with fixed size\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/{base_name}_combined.png', dpi=300, bbox_inches='tight')\n",
    "print(f'{output_dir}/{base_name}_combined.png file saved')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 6. Segmented Image\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plt.imshow(segmented_image)  # No cmap needed - it's already an RGB image\n",
    "plt.title('Improved Segmentation')\n",
    "set_axes_in_meters(ax, segmented_image.shape)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/{base_name}_segmented.png', dpi=300, bbox_inches='tight')\n",
    "print(f'{output_dir}/{base_name}_segmented.png file saved')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 7. Urban Density Map\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "im = plt.imshow(urban_density, cmap='viridis')\n",
    "plt.title('Urban Density Map (0-2 range)')\n",
    "set_axes_in_meters(ax, urban_density.shape)\n",
    "# Add colorbar with fixed size\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/{base_name}_urban_density.png', dpi=300, bbox_inches='tight')\n",
    "print(f'{output_dir}/{base_name}_urban_density.png file saved')\n",
    "#plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 8. Urban Centers\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.gca()\n",
    "plt.imshow(urban_mask, cmap='gray', alpha=0.5)\n",
    "plt.imshow(urban_centers_mask, cmap='Reds', alpha=0.8)\n",
    "plt.title(f\"Urban Centers (Density > {urban_center_threshold})\")\n",
    "set_axes_in_meters(ax, urban_centers_mask.shape)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/{base_name}_urban_centers.png', dpi=300, bbox_inches='tight')\n",
    "print(f'{output_dir}/{base_name}_urban_centers.png file saved')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1111b8ec-1d25-450f-8881-5fa16e3088d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set gradient_intercept to the minimum of the urban density\n",
    "gradient_intercept = urban_density.min()\n",
    "\n",
    "# Calculate density gradients from centers\n",
    "def calculate_density_gradients(centers_mask, urban_mask, density_map):\n",
    "    \"\"\"Calculate how density changes with distance from urban centers\"\"\"\n",
    "    # Calculate distance from each urban pixel to the nearest center\n",
    "    # First invert the centers mask to get distance transform\n",
    "    centers_dist_transform = distance_transform_edt(~centers_mask)\n",
    "    \n",
    "    # Only consider distances within urban areas\n",
    "    urban_distances = centers_dist_transform[urban_mask]\n",
    "    urban_densities = density_map[urban_mask]\n",
    "    \n",
    "    # Bin distances to create gradient profile\n",
    "    max_dist = int(np.max(urban_distances)) + 1\n",
    "    distance_bins = range(max_dist)\n",
    "    density_by_distance = []\n",
    "    \n",
    "    for d in distance_bins:\n",
    "        # Get densities at this distance\n",
    "        mask = (urban_distances >= d) & (urban_distances < d+1)\n",
    "        if np.sum(mask) > 0:\n",
    "            avg_density = np.mean(urban_densities[mask])\n",
    "            density_by_distance.append((d, avg_density))\n",
    "    \n",
    "    return density_by_distance\n",
    "\n",
    "# Calculate density gradients\n",
    "density_gradients = calculate_density_gradients(urban_centers_mask, urban_mask, combined_image)\n",
    "\n",
    "# Density gradient plot data\n",
    "distances = [d for d, _ in density_gradients]\n",
    "densities = [den for _, den in density_gradients]\n",
    "\n",
    "# Convert to numpy arrays for analysis\n",
    "distances_np = np.array(distances)\n",
    "densities_np = np.array(densities)\n",
    "\n",
    "# Convert pixel distances to kilometers using satellite resolution\n",
    "distances_km = distances_np * satellite_pixel_resolution / 1000  # Divide by 1000 to convert m to km\n",
    "\n",
    "# Create a single figure with the density gradient plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot the original density gradient\n",
    "plt.plot(distances_km, densities_np, 'bo-', linewidth=2, label='Density Gradient')\n",
    "\n",
    "# Find local centers (bumps/peaks)\n",
    "if len(distances_np) > 5:\n",
    "    prominence = 0.02 * (max(densities_np) - min(densities_np))\n",
    "    peaks, _ = find_peaks(densities_np, prominence=prominence)\n",
    "    \n",
    "    # Find local minima (valleys)\n",
    "    neg_densities = -1 * densities_np\n",
    "    minima, _ = find_peaks(neg_densities, prominence=prominence)\n",
    "else:\n",
    "    peaks = []\n",
    "    minima = []\n",
    "\n",
    "# Skip the first point - don't add it to minima\n",
    "# Add only last point if needed\n",
    "if (len(distances_np)-1) not in peaks and (len(distances_np)-1) not in minima:\n",
    "    minima = np.append(minima, np.array([len(distances_np)-1]))\n",
    "\n",
    "# Sort minima to ensure they're in ascending order\n",
    "minima = np.sort(minima)\n",
    "\n",
    "# Calculate linear regression through minima\n",
    "if len(minima) > 1:\n",
    "    # Use scipy_stats to avoid conflicts with any existing 'stats' variable\n",
    "    slope_pixel, intercept, r_value, p_value, std_err = scipy_stats.linregress(\n",
    "        distances_np[minima], densities_np[minima])\n",
    "    \n",
    "    # Calculate slope in terms of km\n",
    "    slope_km = slope_pixel * 1000 / satellite_pixel_resolution  # Convert to per-km\n",
    "    \n",
    "    # Create trendline for all points\n",
    "    trendline = slope_pixel * distances_np + intercept\n",
    "    \n",
    "    # Define the y-value for which to calculate the intercept\n",
    "    target_y_value = gradient_intercept  # Example value - adjust as needed\n",
    "    \n",
    "    # Calculate x-value where the line intersects target_y_value\n",
    "    if abs(slope_pixel) > 1e-10:  # Avoid division by near-zero\n",
    "        x_pixels_at_target_y = (target_y_value - intercept) / slope_pixel\n",
    "        ld_distance_min_km = x_pixels_at_target_y * satellite_pixel_resolution / 1000  # Convert to km\n",
    "    else:\n",
    "        x_pixels_at_target_y = float('inf')  # If slope is essentially zero\n",
    "        ld_distance_min_km = float('inf')\n",
    "    \n",
    "    # Plot trendline\n",
    "    plt.plot(distances_km, trendline, 'g--', linewidth=2, \n",
    "             label=f'Alfa: {slope_km:.4f}/km\\nDistance: {ld_distance_min_km:.2f} km')\n",
    "    \n",
    "    # Calculate MSE between actual and trendline\n",
    "    mse = mean_squared_error(densities_np, trendline)\n",
    "else:\n",
    "    mse = 0\n",
    "    ld_distance_min_km = float('inf')\n",
    "\n",
    "# Add horizontal line at center threshold\n",
    "plt.axhline(y=urban_center_threshold, color='r', linestyle='--', alpha=0.7, label=f\"Centers Threshold ({urban_center_threshold})\")\n",
    "\n",
    "# Add target density to legend without drawing a line\n",
    "plt.plot([], [], ' ', label=f\"Target Density ({target_y_value:.2f})\")\n",
    "\n",
    "# If the intercept is within the plot range, mark it\n",
    "if 0 <= ld_distance_min_km <= max(distances_km):\n",
    "    plt.axvline(x=ld_distance_min_km, color='m', linestyle=':', alpha=0.5)\n",
    "    plt.plot(ld_distance_min_km, target_y_value, 'mo', markersize=8)\n",
    "\n",
    "# Set x-axis ticks using the defined interval\n",
    "max_distance_km = np.ceil(max(distances_km))\n",
    "x_ticks = np.arange(0, max_distance_km + 1, gradient_x_tick_interval/1000)  # Convert m to km\n",
    "plt.xticks(x_ticks)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.xlabel('Distance from Urban Center (km)')\n",
    "plt.ylabel('Average Density')\n",
    "plt.title(f'Density Gradient Through Minima (MSE: {mse:.6f})')\n",
    "plt.legend()\n",
    "\n",
    "# Make the plot have good proportions\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/{base_name}_urban_density_gradient.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b777ab3-a2fc-4d16-be3c-d4f71c6c3b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate density gradients from centers\n",
    "def calculate_enhanced_density_gradients(centers_mask, urban_mask, density_map):\n",
    "    \"\"\"Calculate how density changes with distance from urban centers with enhanced statistics\"\"\"\n",
    "    # Calculate distance from each urban pixel to the nearest center\n",
    "    centers_dist_transform = distance_transform_edt(~centers_mask)\n",
    "    \n",
    "    # Only consider distances within urban areas\n",
    "    urban_distances = centers_dist_transform[urban_mask]\n",
    "    urban_densities = density_map[urban_mask]\n",
    "    \n",
    "    # Bin distances to create gradient profile with enhanced statistics\n",
    "    max_dist = int(np.max(urban_distances)) + 1\n",
    "    distance_bins = range(max_dist)\n",
    "    density_stats_by_distance = []\n",
    "    \n",
    "    for d in distance_bins:\n",
    "        # Get densities at this distance\n",
    "        mask = (urban_distances >= d) & (urban_distances < d+1)\n",
    "        if np.sum(mask) > 0:\n",
    "            densities_at_d = urban_densities[mask]\n",
    "            stats = {\n",
    "                \"distance\": d,\n",
    "                \"min\": np.min(densities_at_d),\n",
    "                \"q1\": np.percentile(densities_at_d, 25),\n",
    "                \"median\": np.median(densities_at_d),\n",
    "                \"mean\": np.mean(densities_at_d),\n",
    "                \"q3\": np.percentile(densities_at_d, 75),\n",
    "                \"max\": np.max(densities_at_d)\n",
    "            }\n",
    "            density_stats_by_distance.append(stats)\n",
    "    \n",
    "    return density_stats_by_distance\n",
    "\n",
    "# Calculate enhanced density gradients\n",
    "density_stats = calculate_enhanced_density_gradients(urban_centers_mask, urban_mask, combined_image)\n",
    "\n",
    "# Extract data for plotting - ensure all arrays are created from the same source\n",
    "distances = np.array([stat[\"distance\"] for stat in density_stats])\n",
    "mean_densities = np.array([stat[\"mean\"] for stat in density_stats])\n",
    "median_densities = np.array([stat[\"median\"] for stat in density_stats])\n",
    "min_densities = np.array([stat[\"min\"] for stat in density_stats])\n",
    "max_densities = np.array([stat[\"max\"] for stat in density_stats])\n",
    "q1_densities = np.array([stat[\"q1\"] for stat in density_stats])\n",
    "q3_densities = np.array([stat[\"q3\"] for stat in density_stats])\n",
    "\n",
    "# Convert pixel distances to kilometers using satellite resolution\n",
    "distances_km = distances * satellite_pixel_resolution / 1000  # Divide by 1000 to convert m to km\n",
    "\n",
    "# Set gradient_intercept to the minimum of the Q1 values (minimum of IQR)\n",
    "gradient_intercept = np.min(q1_densities)\n",
    "\n",
    "# Find peaks and minima in the mean density profile\n",
    "if len(distances) > 5:\n",
    "    prominence = 0.02 * (np.max(mean_densities) - np.min(mean_densities))\n",
    "    peaks, _ = find_peaks(mean_densities, prominence=prominence)\n",
    "    \n",
    "    # Find local minima (valleys)\n",
    "    neg_densities = -1 * mean_densities\n",
    "    minima, _ = find_peaks(neg_densities, prominence=prominence)\n",
    "else:\n",
    "    peaks = []\n",
    "    minima = []\n",
    "\n",
    "# Skip the first point - don't add it to minima\n",
    "# Add only last point if needed\n",
    "if (len(distances)-1) not in peaks and (len(distances)-1) not in minima:\n",
    "    minima = np.append(minima, np.array([len(distances)-1]))\n",
    "\n",
    "# Sort minima to ensure they're in ascending order\n",
    "minima = np.sort(minima)\n",
    "\n",
    "# Calculate linear regression through minima\n",
    "if len(minima) > 1:\n",
    "    slope_pixel, intercept, r_value, p_value, std_err = scipy_stats.linregress(\n",
    "        distances[minima], mean_densities[minima])\n",
    "    \n",
    "    # Calculate slope in terms of km\n",
    "    slope_km = slope_pixel * 1000 / satellite_pixel_resolution  # Convert to per-km\n",
    "    \n",
    "    # Create trendline for all points\n",
    "    trendline = slope_pixel * distances + intercept\n",
    "    \n",
    "    # Calculate x-value where the line intersects target_y_value\n",
    "    if abs(slope_pixel) > 1e-10:  # Avoid division by near-zero\n",
    "        x_pixels_at_target_y = (gradient_intercept - intercept) / slope_pixel\n",
    "        ld_distance_irq_km = x_pixels_at_target_y * satellite_pixel_resolution / 1000  # Convert to km\n",
    "    else:\n",
    "        x_pixels_at_target_y = float('inf')  # If slope is essentially zero\n",
    "        ld_distance_irq_km = float('inf')\n",
    "    \n",
    "    # Calculate MSE between actual and trendline\n",
    "    mse = mean_squared_error(mean_densities, trendline)\n",
    "else:\n",
    "    mse = 0\n",
    "    ld_distance_irq_km = float('inf')\n",
    "    slope_km = 0\n",
    "    intercept = 0\n",
    "    trendline = np.zeros_like(distances)\n",
    "\n",
    "# Create enhanced density gradient plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot density ranges\n",
    "plt.fill_between(distances_km, min_densities, max_densities, alpha=0.1, color='blue', label='Min-Max Range')\n",
    "plt.fill_between(distances_km, q1_densities, q3_densities, alpha=0.3, color='blue', label='IQR (25-75%)')\n",
    "\n",
    "# Plot average and median lines\n",
    "plt.plot(distances_km, mean_densities, 'b-', linewidth=2, label='Mean Density')\n",
    "plt.plot(distances_km, median_densities, 'g-', linewidth=1.5, label='Median Density')\n",
    "\n",
    "# Add the trendline\n",
    "if len(minima) > 1:\n",
    "    plt.plot(distances_km, trendline, 'r--', linewidth=2, \n",
    "             label=f'Alfa: {slope_km:.4f}/km\\nDistance: {ld_distance_irq_km:.2f} km')\n",
    "\n",
    "# Add horizontal lines for thresholds\n",
    "plt.axhline(y=urban_center_threshold, color='r', linestyle='--', alpha=0.7, \n",
    "           label=f\"Centers Threshold ({urban_center_threshold})\")\n",
    "plt.axhline(y=urban_threshold, color='orange', linestyle='--', alpha=0.7, \n",
    "           label=f\"Urban Threshold ({urban_threshold})\")\n",
    "plt.axhline(y=gradient_intercept, color='m', linestyle='--', alpha=0.7, \n",
    "           label=f\"IQR Min ({gradient_intercept:.2f})\")\n",
    "\n",
    "# Mark minima points used for regression\n",
    "plt.plot(distances_km[minima], mean_densities[minima], 'rx', markersize=10)\n",
    "\n",
    "# If the intercept is within the plot range, mark it\n",
    "if 0 <= ld_distance_irq_km <= max(distances_km):\n",
    "    plt.axvline(x=ld_distance_irq_km, color='m', linestyle=':', alpha=0.5)\n",
    "    plt.plot(ld_distance_irq_km, gradient_intercept, 'mo', markersize=8)\n",
    "\n",
    "# Set x-axis ticks using the defined interval\n",
    "max_distance_km = np.ceil(max(distances_km))\n",
    "x_ticks = np.arange(0, max_distance_km + 1, gradient_x_tick_interval/1000)  # Convert m to km\n",
    "plt.xticks(x_ticks)\n",
    "\n",
    "plt.xlabel('Distance from Urban Center (km)')\n",
    "plt.ylabel('Density')\n",
    "plt.title(f'Enhanced Density Gradient (MSE: {mse:.6f}, Intercept: {gradient_intercept:.4f})')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and display the plot\n",
    "plt.savefig(f'{output_dir}/{base_name}_enhanced_density_gradient.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa2b397-60cd-45d9-b65e-ee78543ad875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define distance for circle radius\n",
    "ld_distance_km = ld_distance_irq_km / 2\n",
    "\n",
    "# Define center sizse selection for plots\n",
    "center_min_size = 000\n",
    "center_max_size = 5\n",
    "\n",
    "# Find centers of urban center clusters\n",
    "num_centers, center_labels, center_stats, center_centroids = cv2.connectedComponentsWithStats(\n",
    "    urban_centers_mask.astype(np.uint8), connectivity=8)\n",
    "\n",
    "# Convert combined image to a grayscale background\n",
    "# Normalize to 0-255 range\n",
    "background_image = np.clip(combined_image * 255 / combined_image.max(), 0, 255).astype(np.uint8)\n",
    "# Convert to 3-channel grayscale image for colored overlays\n",
    "background_image_rgb = cv2.cvtColor(background_image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# Create a copy for drawing\n",
    "result_image = background_image_rgb.copy()\n",
    "\n",
    "# Create a separate mask for all circles\n",
    "circles_mask = np.zeros_like(result_image)\n",
    "radius_pixels = int(ld_distance_km * 1000 / satellite_pixel_resolution)  # Convert km to pixels\n",
    "\n",
    "# Define red color in RGB format for consistency with matplotlib\n",
    "red_color = (255, 0, 0)  # This is RED in RGB format\n",
    "\n",
    "# Draw all circles on the circles mask\n",
    "for i in range(1, num_centers):\n",
    "    # Skip clusters not in the desired size range\n",
    "    if (center_stats[i, cv2.CC_STAT_AREA] < center_min_size) or (center_stats[i, cv2.CC_STAT_AREA] > center_max_size):\n",
    "        continue\n",
    "        \n",
    "    # Get center coordinates and convert to integers\n",
    "    center_y, center_x = center_centroids[i]\n",
    "    center = (int(center_x), int(center_y))\n",
    "    \n",
    "    # Draw a filled circle on the circles mask (solid red)\n",
    "    cv2.circle(circles_mask, center, radius_pixels, red_color, -1)  # Red filled circle\n",
    "    \n",
    "    # Draw circle boundary in red (same color as fill)\n",
    "    cv2.circle(circles_mask, center, radius_pixels, red_color, 2)  # Red border\n",
    "\n",
    "    break\n",
    "\n",
    "# Now combine the background and circles with proper alpha\n",
    "# Create binary mask where circles exist\n",
    "binary_mask = (circles_mask > 0).any(axis=2)\n",
    "# Apply the circles with alpha=0.2 only where circles exist\n",
    "alpha = 0.2\n",
    "result_image[binary_mask] = cv2.addWeighted(\n",
    "    circles_mask[binary_mask], \n",
    "    alpha, \n",
    "    result_image[binary_mask], \n",
    "    1 - alpha, \n",
    "    0\n",
    ")\n",
    "\n",
    "# Convert to BGR for saving with cv2.imwrite\n",
    "result_image_bgr = cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite(f'data/{base_name}_urban_centers_circles_gray.png', result_image_bgr)\n",
    "\n",
    "# Display using matplotlib (which expects RGB)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(result_image)\n",
    "set_axes_in_meters(plt.gca(), result_image.shape)\n",
    "plt.title(f'Urban Centers with {ld_distance_km:.2f} km Radius Circles')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663ce3f-77e5-4e1b-b0d1-106c2173ae5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
